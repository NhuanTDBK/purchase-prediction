{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"/Users/stevetran/Downloads/VinIDRecruitChallenge/VinIDRecruitChallenge_MLTrack_DataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[\"date\"] = pd.to_datetime(dat[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[\"day_of_week\"] = dat[\"date\"].map(lambda d: d.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.sort_values(by=[\"date\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flatten = pd.read_csv(\"flatten.csv\",date_parser=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flatten[\"date\"] = pd.to_datetime(df_flatten[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flatten.sort_values(by=[\"date\"],ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flatten[\"salesquantity\"] = df_flatten[\"salesquantity\"].map(np.ceil).astype('uint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "Predict which customers make at least 1 purchase in a given month using features generated from the 2 previous months\n",
    "\n",
    "We can rephrase this problem into ML: The probability of repeatable buyers in next month.\n",
    "We limit the problem that are looked back at least two months data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dataset from Feb to July, so we split the dataset\n",
    "- Training: From (Feb, March, April), (March, April, May)\n",
    "- Testing: (April,May,(June,July))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric\n",
    "We evaluate the model using F1 score, False Alarm score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = df_flatten[df_flatten[\"date\"]<=\"2018-06-01\"].copy(deep=True)\n",
    "test_dat = df_flatten[df_flatten[\"date\"]>\"2018-06-01\"].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dat[\"csn\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dat[\"csn\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_items(data):\n",
    "    last_purchases_user_items = {}\n",
    "    items_priors_day = np.zeros(len(data),dtype=\"uint\")\n",
    "    for user_id in data[\"csn\"].unique():\n",
    "        last_purchases_user_items[user_id] = {}\n",
    "        \n",
    "    idx = 0\n",
    "    for _, row in data.sort_values(by=[\"date\"],ascending=True).iterrows():\n",
    "        user_id = row[\"csn\"]\n",
    "        item_id = row[\"article\"]\n",
    "        timestamp = row[\"date\"]\n",
    "        delta = 0\n",
    "        if item_id in last_purchases_user_items[user_id]:        \n",
    "            last_time_purchase = last_purchases_user_items[user_id][item_id]\n",
    "            delta = (timestamp - last_time_purchase).days\n",
    "        last_purchases_user_items[user_id][item_id] = timestamp\n",
    "        items_priors_day[idx] = delta\n",
    "        idx+=1\n",
    "    return items_priors_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dow_features(data):\n",
    "    features = {}\n",
    "    for name, group in data.groupby([\"csn\"]):\n",
    "        dow_cnt = np.zeros(7,dtype=np.uint)\n",
    "        for idx in group[\"date\"].map(lambda d: d.dayofweek).unique():\n",
    "            dow_cnt[idx] += 1        \n",
    "        \n",
    "        features[name] = dow_cnt\n",
    "    return pd.DataFrame(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reorder(data):\n",
    "    features = {}\n",
    "    for name, group in data.groupby([\"csn\"]):\n",
    "        features[name] = {}\n",
    "        sample = group.copy(deep=True)\n",
    "        sample[\"prior_items\"] = calculate_prior_items(sample)        \n",
    "        reorder_products = sample.query(\"prior_items>0\")[\"article\"].nunique()\n",
    "        total_products = sample[\"article\"].nunique()\n",
    "        ratio = 1.0 * reorder_products / total_products\n",
    "        new_products = total_products - reorder_products\n",
    "        \n",
    "        features[name][\"reorder_rate\"] = ratio\n",
    "        features[name][\"new_product\"] = int(new_products)\n",
    "    return pd.DataFrame(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = ['min','max','sum','std','mean','median']\n",
    "def compute_last_n_days(data,time_max,lookbacks=[1,2,3,7,14,21,30]):    \n",
    "    features = {}\n",
    "    for user_id, group in data.groupby([\"csn\"]):\n",
    "        features[user_id] = {}\n",
    "        tmp = {}\n",
    "        \n",
    "#         s1 = time.time()\n",
    "        group = group.set_index([\"date\"])\n",
    "#         s2 = time.time()\n",
    "        \n",
    "        for lookback in lookbacks:\n",
    "            timestamp = time_max - timedelta(days=lookback)\n",
    "            stats = {\n",
    "                    \"unique_products\":0,\n",
    "                    \"total_quantity\": 0,\n",
    "                    \"sales\": 0\n",
    "            }\n",
    "            if timestamp in group.index:\n",
    "                df_filter = group.loc[timestamp:timestamp]\n",
    "                stats = {\n",
    "                    \"unique_products\":df_filter[\"article\"].nunique(),\n",
    "                    \"total_quantity\": df_filter[\"salesquantity\"].sum(),\n",
    "                    \"sales\": df_filter[\"price\"].sum()\n",
    "                }\n",
    "            for k, v in stats.items():\n",
    "                k_features = \"last_{days}_days_{metric}\".format(days=lookback,metric=k)\n",
    "                features[user_id][k_features] = int(v)\n",
    "        \n",
    "#         s3 = time.time()\n",
    "#         print(\"Delta: \",(s2-s1),(s3-s2))\n",
    "        group = group.reset_index()\n",
    "        \n",
    "        last_purchase_date = group[\"date\"].max()\n",
    "        delta_days = (time_max - last_purchase_date).days\n",
    "        features[user_id][\"user_last_purchase_date\"] = int(delta_days)\n",
    "        \n",
    "        features[user_id][\"avg_products_in_cart\"] = group.groupby([\"date\"])[\"article\"].count().mean()\n",
    "        features[user_id][\"number_of_products\"] = group.groupby([\"date\"])[\"article\"].count().sum()\n",
    "        \n",
    "        stats = group.groupby([\"date\"]).agg(\n",
    "        {\n",
    "            \"salesquantity\":agg_func,\n",
    "            \"price\":agg_func\n",
    "        }).mean().reset_index().values\n",
    "        \n",
    "        for i in range(len(stats)):\n",
    "            k1, k2, val = stats[i]\n",
    "            k = k1+\"_\"+k2\n",
    "            features[user_id][k] = val        \n",
    "            \n",
    "    return pd.DataFrame(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_df(df_train,df_test,time_max):\n",
    "    df_last_purchase = compute_last_n_days(df_train,time_max=time_max)\n",
    "    df_dow_features = calculate_dow_features(df_train)\n",
    "    df_reorder_features = calculate_reorder(df_train)\n",
    "\n",
    "    df_reorder_features[\"new_product\"] = df_reorder_features[\"new_product\"].astype('uint')\n",
    "    df_features = df_last_purchase.join(df_reorder_features).join(df_dow_features)\\\n",
    "        .copy(deep=True)\\\n",
    "        .reset_index().rename({\"index\":\"csn\"},axis=1)\n",
    "    test_csn = set(df_test[\"csn\"].unique())\n",
    "    df_features[\"label\"] = df_features[\"csn\"].map(lambda d: 1 if d in test_csn else 0)\n",
    "    print(df_features[\"label\"].value_counts())\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_times = [\"2018-02-01\",\"2018-04-01\",\"2018-06-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  2018-02-01\n",
      "0    12344\n",
      "1      940\n",
      "Name: label, dtype: int64\n",
      "Processing  2018-04-01\n",
      "0    11930\n",
      "1      783\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_total = []\n",
    "for i in range(len(train_times)-1):\n",
    "    print(\"Processing \", train_times[i])\n",
    "    start = train_times[i]\n",
    "    end = train_times[i+1]\n",
    "    train_df = df_flatten[(df_flatten[\"date\"]>=start)&(df_flatten[\"date\"]<end)]\n",
    "    test_df = df_flatten[df_flatten[\"date\"]==end]\n",
    "    X_total.append(get_features_from_df(train_df,test_df,time_max=datetime.strptime(end,\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.concat(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24274\n",
       "1     1723\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set(df_flatten[df_flatten[\"date\"]<\"2018-04-01\"][\"csn\"].unique())\n",
    "e = set(df_flatten[df_flatten[\"date\"]==\"2018-04-01\"][\"csn\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv(\"df_features.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_nan = df_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features_nan.drop([\"csn\",\"label\"],axis=1).values\n",
    "y = df_features[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7140785194014518"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(estimator=RandomForestClassifier(n_estimators=200),X=X,y=y,cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7173650737412289"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(estimator=lightgbm.LGBMClassifier(n_estimators=200,\n",
    "                                                          subsample=0.5,                                                          \n",
    "                                                          learning_rate=0.01)\n",
    "                        ,X=X,y=y,cv=5,scoring='f1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = PolynomialFeatures(degree=2,include_bias=True).fit_transform(MinMaxScaler().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223754353136805"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(estimator=LogisticRegression(max_iter=10000),X=X_transform,y=y,cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7226427842227222"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(estimator=LinearSVC(verbose=1,max_iter=10000),X=X_transform,y=y,cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_last_purchase_date', 0.09270921295688098),\n",
       " ('total_price', 0.08040146923220215),\n",
       " ('new_product', 0.07458550040192596),\n",
       " ('reorder_rate', 0.069687772341471),\n",
       " ('total_quantity', 0.06851739927885359),\n",
       " ('avg_products_in_cart', 0.05517071891527061),\n",
       " ('min_price', 0.053651661224843425),\n",
       " ('max_price', 0.051624950769237433),\n",
       " ('median_price', 0.051318421020260636),\n",
       " ('std_price', 0.05086377695754538),\n",
       " ('avg_price', 0.050302122472754396),\n",
       " ('std_quantity', 0.04068498468958489),\n",
       " ('avg_quantity', 0.039990677890787904),\n",
       " ('max_quantity', 0.026872590759219127),\n",
       " (4, 0.018710782829700585),\n",
       " (2, 0.01823570638784496),\n",
       " (5, 0.016400606374980926),\n",
       " (0, 0.014440114683809247),\n",
       " (1, 0.012550201819167332),\n",
       " (3, 0.012118820674511845),\n",
       " (6, 0.009807469623870146),\n",
       " ('median_quantity', 0.007873396913385313),\n",
       " ('last_7_days_sales', 0.004471364986592645),\n",
       " ('last_21_days_unique_products', 0.004403468603888407),\n",
       " ('last_35_days_sales', 0.004399784241720509),\n",
       " ('last_21_days_sales', 0.004308634364850487),\n",
       " ('last_21_days_total_quantity', 0.004291966967258275),\n",
       " ('last_1_days_sales', 0.0041567462086162365),\n",
       " ('last_7_days_unique_products', 0.004039547152268201),\n",
       " ('last_7_days_total_quantity', 0.003985808783220557),\n",
       " ('last_1_days_total_quantity', 0.003966662801949148),\n",
       " ('last_14_days_sales', 0.0039551599600961326),\n",
       " ('last_35_days_unique_products', 0.00385572370987508),\n",
       " ('last_14_days_unique_products', 0.0037671533550784706),\n",
       " ('last_35_days_total_quantity', 0.0037559255453380887),\n",
       " ('last_14_days_total_quantity', 0.003625608184406186),\n",
       " ('last_2_days_sales', 0.0033819170612702444),\n",
       " ('last_1_days_unique_products', 0.003118348291232346),\n",
       " ('last_2_days_total_quantity', 0.00292747788898817),\n",
       " ('last_2_days_unique_products', 0.0026959000109548405),\n",
       " ('last_30_days_sales', 0.0025785765097342678),\n",
       " ('last_3_days_sales', 0.002313648999443133),\n",
       " ('last_30_days_total_quantity', 0.0023094323129708477),\n",
       " ('last_30_days_unique_products', 0.0020283834809505536),\n",
       " ('last_3_days_total_quantity', 0.001945047907309577),\n",
       " ('last_3_days_unique_products', 0.001882900046139955),\n",
       " ('min_quantity', 0.0013164544077397652)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(df_features.drop([\"csn\",\"label\"],axis=1).columns,rf.feature_importances_))\n",
    "       ,key=lambda d: d[-1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
